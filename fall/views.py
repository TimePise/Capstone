from django.http import StreamingHttpResponse, JsonResponse
import torch
import numpy as np
import cv2
import mediapipe as mp
import os
import threading
from django.conf import settings
from .models import FallAlert
from channels.layers import get_channel_layer
from asgiref.sync import async_to_sync
from .model_gru import FallBiGRUAttentionNet
import pygame
import time
from datetime import datetime

pose_thread_started = False

def start_pose_thread_once():
    global pose_thread_started
    if not pose_thread_started:
        print("ğŸ“¡ ë‚™ìƒ ê°ì§€ ì“°ë ˆë“œ ì‹œì‘ë¨")
        t = threading.Thread(target=generate_pose_estimation, daemon=True)
        t.start()
        pose_thread_started = True

# ì „ì—­ ìƒíƒœ
privacy_mode = False
last_fall_label = "ì •ìƒì…ë‹ˆë‹¤"
last_fall_pred = 0
alarm_cooldown = 0
ALARM_INTERVAL = 5  # ìµœì†Œ ì•Œë¦¼ ê°„ê²© (ì´ˆ ë‹¨ìœ„)

# ëª¨ë¸ ì¤€ë¹„
SELECTED_IDX = [0, 10, 15, 16, 23, 24]
model = FallBiGRUAttentionNet(input_dim=24, hidden_dim=128, num_layers=2, fall_classes=2, part_classes=4)
model_path = os.path.join(settings.BASE_DIR, 'fall', 'fall_bigru_model.pth')
model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
model.eval()

# MediaPipe ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()
mp_drawing = mp.solutions.drawing_utils

# ì•ŒëŒ ì„¤ì •
ALARM_PATH = os.path.join(settings.BASE_DIR, 'fall', 'fall_alert.mp3')

def play_alarm():
    try:
        pygame.mixer.init()
        pygame.mixer.music.load(ALARM_PATH)
        pygame.mixer.music.play()
    except Exception as e:
        print("âŒ ì•ŒëŒ ì‹¤íŒ¨:", e)

def toggle_privacy_mode(request):
    global privacy_mode
    privacy_mode = not privacy_mode
    return JsonResponse({'privacy_mode': privacy_mode})

def fall_status(request):
    return JsonResponse({
        'label': last_fall_label,
        'fall': last_fall_pred == 1
    })

def reset_alert_lock(request):
    return JsonResponse({'status': 'reset complete'})

def generate_pose_estimation():
    global privacy_mode, last_fall_label, last_fall_pred, alarm_cooldown
    from .models import FallAlert

    sequence = []
    prev_zs = None
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("âŒ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨")
        return

    try:
        while cap.isOpened():
            ret, original_frame = cap.read()
            if not ret:
                break

            original_frame = cv2.flip(original_frame, 1)
            rgb = cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB)
            result = pose.process(rgb)

            frame = np.zeros_like(original_frame) if privacy_mode else original_frame.copy()

            label = "ì •ìƒì…ë‹ˆë‹¤"
            color = (0, 255, 0)
            fall_pred = 0

            if result.pose_landmarks:
                keypoints = []
                current_zs = []

                for idx in SELECTED_IDX:
                    lm = result.pose_landmarks.landmark[idx]
                    current_zs.append(lm.z)

                for i, idx in enumerate(SELECTED_IDX):
                    lm = result.pose_landmarks.landmark[idx]
                    z_now = lm.z
                    z_prev = prev_zs[i] if prev_zs else z_now
                    speed_z = z_now - z_prev
                    keypoints.extend([lm.x, lm.y, lm.z, speed_z])

                prev_zs = current_zs
                sequence.append(keypoints)

                if len(sequence) >= 30:
                    input_seq = np.array(sequence[-30:])
                    input_tensor = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0)
                    with torch.no_grad():
                        fall_out, _ = model(input_tensor)
                        fall_pred = torch.argmax(fall_out, dim=1).item()

                        if fall_pred == 1:
                            current_time = time.time()
                            if current_time - alarm_cooldown >= ALARM_INTERVAL:
                                alarm_cooldown = current_time

                                z_parts = {
                                    "ë¨¸ë¦¬": min(result.pose_landmarks.landmark[i].z for i in [0, 10]),
                                    "ì†ëª©": min(result.pose_landmarks.landmark[i].z for i in [15, 16]),
                                    "ê³¨ë°˜": min(result.pose_landmarks.landmark[i].z for i in [23, 24]),
                                }
                                part = min(z_parts, key=z_parts.get)
                                label = f"{part} ì¤‘ì‹¬ ë‚™ìƒ ë°œìƒ"
                                color = (0, 0, 255)
                                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                                threading.Thread(target=play_alarm, daemon=True).start()

                                FallAlert.objects.create(
                                    message=label,
                                    part=part,
                                    fall_level="ì‹¬ê°",
                                    name="í™˜ìA",
                                    room_number="101í˜¸",
                                    is_read=False
                                )

                                channel_layer = get_channel_layer()
                                async_to_sync(channel_layer.group_send)(
                                    "fall_alert_group",
                                    {
                                        "type": "send_alert",
                                        "message": label,
                                        "name": "í™˜ìA",
                                        "room_number": "101í˜¸",
                                        "fall_level": "ì‹¬ê°",
                                        "part": part,
                                        "timestamp": timestamp
                                    }
                                )
                        else:
                            label = "ì •ìƒì…ë‹ˆë‹¤"
                            color = (0, 255, 0)

            last_fall_label = label
            last_fall_pred = fall_pred

            if result.pose_landmarks:
                landmark_spec = mp_drawing.DrawingSpec(
                    color=(255, 255, 255) if privacy_mode else (0, 255, 255),
                    thickness=4, circle_radius=4
                )
                connection_spec = mp_drawing.DrawingSpec(
                    color=(255, 255, 255) if privacy_mode else (0, 255, 255),
                    thickness=3
                )
                mp_drawing.draw_landmarks(
                    frame,
                    result.pose_landmarks,
                    mp_pose.POSE_CONNECTIONS,
                    landmark_drawing_spec=landmark_spec,
                    connection_drawing_spec=connection_spec
                )

            _, buffer = cv2.imencode('.jpg', frame)

            try:
                yield (
                    b'--frame\r\n'
                    b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n'
                )
                time.sleep(0.05)
            except GeneratorExit:
                print("ğŸ›‘ì—°ê²° ì¢…ë£Œë¨")
                break
            except Exception as e:
                print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡ ì˜¤ë¥˜: {e}")
                break

    except Exception as e:
        print(f"âŒ ë£¨í”„ ë‚´ë¶€ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        cap.release()
        print("ğŸ“· ì¹´ë©”ë¼ ìì› í•´ì œ ì™„ë£Œ")

def pose_estimation_feed(request):
    try:
        return StreamingHttpResponse(
            generate_pose_estimation(),
            content_type='multipart/x-mixed-replace; boundary=frame',
        )
    except Exception as e:
        print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
        return JsonResponse({"error": "ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨"}, status=500)

def fall_alert_stream(request):
    def event_stream():
        last_sent = None
        while True:
            alert = FallAlert.objects.filter(is_read=False).order_by('-timestamp').first()
            if alert and alert.timestamp != last_sent:
                last_sent = alert.timestamp
                yield f"data: {alert.message}\n\n"
            time.sleep(1)  # 1ì´ˆë§ˆë‹¤ í™•ì¸

    return StreamingHttpResponse(event_stream(), content_type='text/event-stream')